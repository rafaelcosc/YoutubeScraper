{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWkt5NOLmhUf",
        "outputId": "be2714d0-8c0f-4b5e-8c74-e1cf2782fa99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define vars\n",
        "PATH_DEVELOP = 'test_dev'\n",
        "PATH_PRODUCTION = 'test_prod'\n",
        "START_DAY = 1\n",
        "START_MON = 1\n",
        "START_YEAR = 2022\n",
        "\n",
        "END_DAY = 1\n",
        "END_MON = 7\n",
        "END_YEAR = 2023\n",
        "\n",
        "# Define what channel id you will use\n",
        "channel_id = 'UCWdGgeyOnCOGnvhNdbVl1dQ'\n",
        "\n",
        "# Define the API key from Google Cloud Console\n",
        "API_KEY = \"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "w3-ci2A3_UaB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_DEV = \"/content/drive/My Drive/\" + PATH_DEVELOP + '/'\n",
        "PATH_PROD = \"/content/drive/My Drive/\" + PATH_PRODUCTION + '/'\n",
        "\n",
        "!mkdir -p \"{PATH_DEV}\"\n",
        "!mkdir -p \"{PATH_PROD}\""
      ],
      "metadata": {
        "id": "5wrTGxk3Cqwq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import os\n",
        "from googleapiclient.discovery import build\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import time"
      ],
      "metadata": {
        "id": "RaNdBhg_jDil"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zMEfUuymh7o"
      },
      "outputs": [],
      "source": [
        "YOUTUBE_API_SERVICE_NAME = \"youtube\"\n",
        "YOUTUBE_API_VERSION = \"v3\"\n",
        "\n",
        "youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey=API_KEY)\n",
        "\n",
        "def get_all_videos_from_channel(channel_id, start_date, end_date):\n",
        "    video_ids = []\n",
        "    video_titles = []\n",
        "    video_dates = []\n",
        "    token = None\n",
        "    formatted_date = f\"{END_YEAR}-{END_MON:02d}-{END_DAY:02d}T00:00:00Z\"\n",
        "\n",
        "    stop_search = 1\n",
        "\n",
        "    while stop_search:\n",
        "\n",
        "      search_params = {\n",
        "          'channelId': channel_id,\n",
        "          'type': \"video\",\n",
        "          'part': \"id,snippet\",\n",
        "          'maxResults': 50,\n",
        "          'order': 'date',\n",
        "          'publishedBefore' : formatted_date,\n",
        "          'pageToken': token\n",
        "      }\n",
        "\n",
        "\n",
        "\n",
        "      search_response = youtube.search().list(**search_params).execute()\n",
        "\n",
        "      for search_result in search_response.get(\"items\", []):\n",
        "        publish_date = search_result[\"snippet\"][\"publishedAt\"]\n",
        "\n",
        "        video_date = datetime.strptime(publish_date, '%Y-%m-%dT%H:%M:%SZ')\n",
        "        if(start_date <= video_date <= end_date):\n",
        "          video_ids.append(search_result[\"id\"][\"videoId\"])\n",
        "          video_titles.append(search_result[\"snippet\"][\"title\"])\n",
        "          video_dates.append(publish_date)\n",
        "        if(start_date > video_date):\n",
        "          stop_search = 0\n",
        "\n",
        "        print(video_date)\n",
        "      try:\n",
        "        print(search_response[\"nextPageToken\"])\n",
        "        token = search_response[\"nextPageToken\"]\n",
        "      except:\n",
        "        print('Não existe mais token ultima pagina obtida!')\n",
        "        stop_search = 0\n",
        "\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        'Video ID': video_ids,\n",
        "        'Video Title': video_titles,\n",
        "        'Post Date': video_dates\n",
        "    })\n",
        "\n",
        "    return df\n",
        "\n",
        "start_date = datetime(START_YEAR, START_MON, START_DAY)\n",
        "end_date = datetime(END_YEAR, END_MON, END_DAY)\n",
        "\n",
        "df = get_all_videos_from_channel(channel_id, start_date, end_date)\n",
        "df.to_csv(PATH_DEV + 'index.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fywVNnKGouD_"
      },
      "outputs": [],
      "source": [
        "def get_all_comments_from_video(video_id):\n",
        "    comments = []\n",
        "    token = None\n",
        "\n",
        "    while True:\n",
        "        search_params = {\n",
        "            'videoId': video_id,\n",
        "            'part': \"snippet\",\n",
        "            'maxResults': 50,\n",
        "            'pageToken': token\n",
        "        }\n",
        "\n",
        "        search_response = youtube.commentThreads().list(**search_params).execute()\n",
        "\n",
        "        for item in search_response.get('items', []):\n",
        "            comment = item['snippet']['topLevelComment']['snippet']\n",
        "            comments.append([\n",
        "                comment['authorDisplayName'],\n",
        "                comment['publishedAt'],\n",
        "                comment['updatedAt'],\n",
        "                comment['likeCount'],\n",
        "                comment['textDisplay']\n",
        "            ])\n",
        "\n",
        "        try:\n",
        "          token = search_response[\"nextPageToken\"]\n",
        "        except:\n",
        "          break\n",
        "\n",
        "    df = pd.DataFrame(comments, columns=['author', 'published_at', 'updated_at', 'like_count', 'text'])\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zbHe_jL1xDT"
      },
      "outputs": [],
      "source": [
        "df_index = pd.read_csv(PATH_DEV + 'index.csv')\n",
        "\n",
        "lista_csv = !ls \"{PATH_DEV}\"\n",
        "processed_list = []\n",
        "for item in lista_csv:\n",
        "    split_items = item.split('\\t')\n",
        "    processed_list.extend([s.replace('.csv', '') for s in split_items])\n",
        "\n",
        "file_list = []\n",
        "\n",
        "for item in processed_list:\n",
        "    file_list.extend(item.split())\n",
        "\n",
        "lista_id = df_index['Video ID']\n",
        "\n",
        "missing_ids = [vid_id for vid_id in lista_id if vid_id not in file_list]\n",
        "len(missing_ids)\n",
        "for id_nao_processado in missing_ids:\n",
        "  print(id_nao_processado)\n",
        "  df = get_all_comments_from_video(id_nao_processado)\n",
        "  df.to_csv(PATH_DEV + id_nao_processado + '.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_index = pd.read_csv(PATH_DEV + 'index.csv')\n",
        "\n",
        "for index, row in df_index.iterrows():\n",
        "\n",
        "    try:\n",
        "      read_file = pd.read_csv(PATH_DEV + row['Video ID'] + '.csv', engine='python')\n",
        "      date_obj = datetime.strptime(row['Post Date'], \"%Y-%m-%dT%H:%M:%SZ\")\n",
        "      formatted_date = date_obj.strftime(\"%Y%m%d\")\n",
        "      safe_title = re.sub(r'[^a-zA-Z0-9 ]', '', row['Video Title'])\n",
        "      file_name = f'{safe_title.replace(\" \", \"_\")}'\n",
        "      new_file_name = formatted_date + ';' + file_name + ';' + row['Video ID'] + ';' + f'{str(len(read_file) -1)}'+'.csv'\n",
        "      read_file.to_csv(PATH_PROD + new_file_name,index=False)\n",
        "      print(PATH_PROD + new_file_name + ' --> Arquivo inserido com sucesso')\n",
        "    except:\n",
        "      print(PATH_DEV + row['Video ID'] + '.csv' + ' --> Arquivo não foi encontrado')"
      ],
      "metadata": {
        "id": "1-3dPLSZeK1-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}